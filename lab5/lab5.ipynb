{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LAB-ANAPHORA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLL-p1UrGZHa",
        "colab_type": "text"
      },
      "source": [
        "### Anaphora resolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RQCPVBkGZHb",
        "colab_type": "text"
      },
      "source": [
        "1) Get the pretrained model of FastText from https://fasttext.cc/docs/en/english-vectors.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnY0bW9zGZHc",
        "colab_type": "text"
      },
      "source": [
        "2) At the pytorch develop a model, that is a feed forward neural network that consists of three layers, an input layer of size 600, a first layer of size 300, a second layer of 80 and an output layer with two units, all layers have regularization and dropout. The activation function on all layers is ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgNAXlPmGZHc",
        "colab_type": "text"
      },
      "source": [
        "![scheme.jpg](attachment:scheme.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wEQ09zGZHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng7rBifnGaKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "beb39fad-ae41-4e1e-a7fd-c1fd0a945351"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRp8T2eoGZHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_dev = pd.read_csv('/content/drive/My Drive/gap-development.tsv',sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdDaXeNsGZHk",
        "colab_type": "text"
      },
      "source": [
        "The task is to identify the target of a pronoun within a text passage. The source text is taken from Wikipedia articles. In the dataset, there are labels of the pronoun and two candidate names to which the pronoun could refer. An algorithm should be capable of deciding whether the pronoun refers to name A, name B, or neither.  \n",
        "There are the following columns for analysis:\n",
        "* ID - Unique identifier for an example (Matches to Id in output file format);\n",
        "* Text - Text containing the ambiguous pronoun and two candidate names (about a paragraph in length);\n",
        "* Text - Text containing the ambiguous pronoun and two candidate names (about a paragraph in length);\n",
        "* Pronoun - The target pronoun (text);\n",
        "* Pronoun-offset The character offset of Pronoun in Text;\n",
        "* A - The first name candidate (text);\n",
        "* A-offset - The character offset of name A in Text;\n",
        "* B - The second name candidate;\n",
        "* B-offset - The character offset of name B in Text;\n",
        "* URL - The URL of the source Wikipedia page for the example;\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxzdETdNGZHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "74c034ce-0a96-4cf6-b212-92b32939b363"
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>development-1</td>\n",
              "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
              "      <td>her</td>\n",
              "      <td>274</td>\n",
              "      <td>Cheryl Cassidy</td>\n",
              "      <td>191</td>\n",
              "      <td>True</td>\n",
              "      <td>Pauline</td>\n",
              "      <td>207</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>development-2</td>\n",
              "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
              "      <td>His</td>\n",
              "      <td>284</td>\n",
              "      <td>MacKenzie</td>\n",
              "      <td>228</td>\n",
              "      <td>True</td>\n",
              "      <td>Bernard Leach</td>\n",
              "      <td>251</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>development-3</td>\n",
              "      <td>He had been reelected to Congress, but resigne...</td>\n",
              "      <td>his</td>\n",
              "      <td>265</td>\n",
              "      <td>Angeloz</td>\n",
              "      <td>173</td>\n",
              "      <td>False</td>\n",
              "      <td>De la Sota</td>\n",
              "      <td>246</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>development-4</td>\n",
              "      <td>The current members of Crime have also perform...</td>\n",
              "      <td>his</td>\n",
              "      <td>321</td>\n",
              "      <td>Hell</td>\n",
              "      <td>174</td>\n",
              "      <td>False</td>\n",
              "      <td>Henry Rosenthal</td>\n",
              "      <td>336</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>development-5</td>\n",
              "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
              "      <td>She</td>\n",
              "      <td>437</td>\n",
              "      <td>Kitty Oppenheimer</td>\n",
              "      <td>219</td>\n",
              "      <td>False</td>\n",
              "      <td>Rivera</td>\n",
              "      <td>294</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID  ...                                                URL\n",
              "0  development-1  ...  http://en.wikipedia.org/wiki/List_of_Teachers_...\n",
              "1  development-2  ...      http://en.wikipedia.org/wiki/Warren_MacKenzie\n",
              "2  development-3  ...  http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...\n",
              "3  development-4  ...          http://en.wikipedia.org/wiki/Crime_(band)\n",
              "4  development-5  ...        http://en.wikipedia.org/wiki/Jessica_Rivera\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEISET1IGZHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "26bda007-39a4-44e4-db1c-6e681b76c746"
      },
      "source": [
        "df_dev.iloc[0]['Text']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Cheryl Cassidy, Pauline's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Pauline.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Into8ZYlG0jJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f637131e-83e3-4ab3-f61d-999bb02e6017"
      },
      "source": [
        "df_dev.iloc[0]['Pronoun']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'her'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6G5tWo6GZHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_val = pd.read_csv('/content/drive/My Drive/gap-validation.tsv',sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-fcP5xDGZHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "6b73b281-56b6-472d-a498-ba9990a5ba23"
      },
      "source": [
        "df_val.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Pronoun</th>\n",
              "      <th>Pronoun-offset</th>\n",
              "      <th>A</th>\n",
              "      <th>A-offset</th>\n",
              "      <th>A-coref</th>\n",
              "      <th>B</th>\n",
              "      <th>B-offset</th>\n",
              "      <th>B-coref</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>validation-1</td>\n",
              "      <td>He admitted making four trips to China and pla...</td>\n",
              "      <td>him</td>\n",
              "      <td>256</td>\n",
              "      <td>Jose de Venecia Jr</td>\n",
              "      <td>208</td>\n",
              "      <td>False</td>\n",
              "      <td>Abalos</td>\n",
              "      <td>241</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>validation-2</td>\n",
              "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
              "      <td>She</td>\n",
              "      <td>185</td>\n",
              "      <td>Ellen</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>Kathleen</td>\n",
              "      <td>150</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>validation-3</td>\n",
              "      <td>When she returns to her hotel room, a Liberian...</td>\n",
              "      <td>his</td>\n",
              "      <td>435</td>\n",
              "      <td>Jason Scott Lee</td>\n",
              "      <td>383</td>\n",
              "      <td>False</td>\n",
              "      <td>Danny</td>\n",
              "      <td>406</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>validation-4</td>\n",
              "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
              "      <td>he</td>\n",
              "      <td>333</td>\n",
              "      <td>Reucassel</td>\n",
              "      <td>300</td>\n",
              "      <td>True</td>\n",
              "      <td>Debnam</td>\n",
              "      <td>325</td>\n",
              "      <td>False</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>validation-5</td>\n",
              "      <td>By this time, Karen Blixen had separated from ...</td>\n",
              "      <td>she</td>\n",
              "      <td>427</td>\n",
              "      <td>Finch Hatton</td>\n",
              "      <td>290</td>\n",
              "      <td>False</td>\n",
              "      <td>Beryl Markham</td>\n",
              "      <td>328</td>\n",
              "      <td>True</td>\n",
              "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             ID  ...                                                URL\n",
              "0  validation-1  ...  http://en.wikipedia.org/wiki/Commission_on_Ele...\n",
              "1  validation-2  ...         http://en.wikipedia.org/wiki/Kathleen_Nott\n",
              "2  validation-3  ...  http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...\n",
              "3  validation-4  ...       http://en.wikipedia.org/wiki/Craig_Reucassel\n",
              "4  validation-5  ...    http://en.wikipedia.org/wiki/Denys_Finch_Hatton\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq-t_NW5GZH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Put your code here\n",
        "\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from gensim.models.fasttext import FastText as FT_gensim\n",
        "fasttext = FT_gensim.load_fasttext_format('/content/drive/My Drive/wiki.en.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5uIaPMXHFLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb5f321-3358-4fa9-c06e-796a79c92e7c"
      },
      "source": [
        "import torch\n",
        "train_data_X = []\n",
        "for i in range(len(df_dev['Text'])):\n",
        "    temp1 = np.append(fasttext.wv[df_dev['Text'][i]],fasttext.wv[df_dev['Pronoun'][i]])\n",
        "    temp2 = np.append(temp1, fasttext.wv[df_dev['A'][i]])\n",
        "    to_train = np.append(temp2, fasttext.wv[df_dev['B'][i]])\n",
        "    train_data_X.append(to_train)\n",
        "X = torch.tensor(train_data_X).float()\n",
        "print('train_data_X size: ', len(X[0]))\n",
        "\n",
        "train_data_y = []\n",
        "y1 = df_dev['A-coref'].replace(True,1)\n",
        "y2 = df_dev['B-coref'].replace(True,1)\n",
        "for i in range(len(X)):\n",
        "    temp = np.append(y1[i],y2[i])\n",
        "    train_data_y.append(temp)\n",
        "Y = torch.tensor(train_data_y).float()\n",
        "print('train_data_Y size: ', len(Y[0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data_X size:  1200\n",
            "train_data_Y size:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GFEBfCADQEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(myNN, self).__init__()\n",
        "        self.classificator = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.3),\n",
        "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.3),\n",
        "            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = 0.3),\n",
        "            nn.Linear(hidden_sizes[2], output_size)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        output = self.classificator(x)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbiICTJ5Iosv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "8f514e0f-77e4-4ae3-f16d-07499c60d68a"
      },
      "source": [
        "input_size = len(X[0])\n",
        "hidden_sizes = [600,300, 80]\n",
        "output_size = 2\n",
        "\n",
        "model = myNN(input_size, hidden_sizes, output_size)\n",
        "loss_fn = torch.nn.SmoothL1Loss()\n",
        "learning_rate = 0.0001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_arr = []\n",
        "num_epochs = 5000\n",
        "for i in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    Y_pred = model(X)\n",
        "    loss = loss_fn(Y_pred, Y)\n",
        "    loss_arr.append(loss)\n",
        "    if (i%100 == 0):\n",
        "        print(i, loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.2229291796684265\n",
            "100 0.10748165845870972\n",
            "200 0.033215489238500595\n",
            "300 0.01558914314955473\n",
            "400 0.011182235553860664\n",
            "500 0.008277066051959991\n",
            "600 0.007584089878946543\n",
            "700 0.007566582877188921\n",
            "800 0.006402725353837013\n",
            "900 0.005981431808322668\n",
            "1000 0.005745122209191322\n",
            "1100 0.005393362604081631\n",
            "1200 0.005227705929428339\n",
            "1300 0.005042365752160549\n",
            "1400 0.004929412622004747\n",
            "1500 0.004497047048062086\n",
            "1600 0.004479686263948679\n",
            "1700 0.004173140972852707\n",
            "1800 0.004321929533034563\n",
            "1900 0.00401674909517169\n",
            "2000 0.004123984836041927\n",
            "2100 0.003990926314145327\n",
            "2200 0.003909176215529442\n",
            "2300 0.0037602342199534178\n",
            "2400 0.0037679080851376057\n",
            "2500 0.00379855465143919\n",
            "2600 0.0035868908744305372\n",
            "2700 0.003360231639817357\n",
            "2800 0.0034095770679414272\n",
            "2900 0.003370582824572921\n",
            "3000 0.0034072112757712603\n",
            "3100 0.003126344410702586\n",
            "3200 0.003177874954417348\n",
            "3300 0.003011175896972418\n",
            "3400 0.0030276658944785595\n",
            "3500 0.0030500278808176517\n",
            "3600 0.0029946202412247658\n",
            "3700 0.002961772261187434\n",
            "3800 0.0028112006839364767\n",
            "3900 0.003007519757375121\n",
            "4000 0.002839894499629736\n",
            "4100 0.0028475455474108458\n",
            "4200 0.002822448732331395\n",
            "4300 0.002801221329718828\n",
            "4400 0.0027946659829467535\n",
            "4500 0.0026331215631216764\n",
            "4600 0.0026040670927613974\n",
            "4700 0.0027025428134948015\n",
            "4800 0.002514009829610586\n",
            "4900 0.002585507230833173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVKlu4pNI-K0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "44a6a226-0220-47fb-afaa-4dc6c7d28876"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epoch = []\n",
        "for i in range (len(loss_arr)):\n",
        "    epoch.append(i)\n",
        "plt.plot(epoch, loss_arr)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR1Ohy5QJb3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9f74b54e-bb26-481c-feec-68d62ca097cd"
      },
      "source": [
        "val_data_length = len(df_val['Text'])\n",
        "test_data_X = []\n",
        "for i in range(val_data_length):\n",
        "    temp1 = np.append(fasttext.wv[df_val['Text'][i]], fasttext.wv[df_val['Pronoun'][i]])\n",
        "    temp2 = np.append(temp1, fasttext.wv[df_val['A'][i]])\n",
        "    to_test = np.append(temp2, fasttext.wv[df_val['B'][i]])\n",
        "    test_data_X.append(to_test)\n",
        "X_test = torch.tensor(test_data_X).float()\n",
        "print('test_data_X size: ', len(X_test[0]))\n",
        "\n",
        "test_data_y = []\n",
        "y1 = (df_val['A-coref'].replace(True, 1).values)\n",
        "y2 = (df_val['B-coref'].replace(True, 1).values)\n",
        "for i in range(val_data_length):\n",
        "    temp = np.append(y1[i],y2[i])\n",
        "    test_data_y.append(temp)\n",
        "Y_test = torch.tensor(test_data_y).float()\n",
        "print('test_data_Y size: ', len(Y_test[0]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data_X size:  1200\n",
            "test_data_Y size:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iWF7dlzKXtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred = model(X_test)\n",
        "#y_test_pred_np = y_test_pred.detach().numpy()\n",
        "y_test_pred_np = (np.round((y_test_pred).detach().numpy() ))**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNj2lpV5TdUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc072ced-3213-4e1a-a89e-69c7a541a236"
      },
      "source": [
        "y_test_pred_np"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA_wRCrzMpM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_class = []\n",
        "for i in range (len(Y_test)):\n",
        "    y_test2 = Y_test[i].detach().numpy()\n",
        "    if (y_test2[0] == 0):\n",
        "        if (y_test2[1] == 0):\n",
        "            y_test_class.append('false-negative')\n",
        "    if (y_test2[0] == 0):\n",
        "        if (y_test2[1] == 1):\n",
        "            y_test_class.append('false-positive')\n",
        "    if (y_test2[0]== 1):\n",
        "        if (y_test2[1]== 0):\n",
        "            y_test_class.append('true-negative')\n",
        "    if (y_test2[0]== 1):\n",
        "        if (y_test2[1] == 1):\n",
        "            y_test_class.append('true-positive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0DnJailM6RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred_class = []\n",
        "for i in range (len(y_test_pred_np)):\n",
        "    y_test2 = y_test_pred_np[i]\n",
        "    if (y_test2[0] == 0):\n",
        "        if (y_test2[1] == 0):\n",
        "            y_test_pred_class.append('false-negative')\n",
        "    if (y_test2[0] ==0):\n",
        "        if (y_test2[1] == 1):\n",
        "            y_test_pred_class.append('false-positive')\n",
        "    if (y_test2[0] == 1):\n",
        "        if (y_test2[1] == 0):\n",
        "            y_test_pred_class.append('true-negative')\n",
        "    if (y_test2[0] == 1):\n",
        "        if (y_test2[1] == 1):\n",
        "            y_test_pred_class.append('true-positive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKAJAoDUNGZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "e748d7e2-0833-4c6d-ce45-f662721e63bf"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clr = classification_report(y_test_class, y_test_pred_class)\n",
        "print(clr)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "false-negative       0.24      0.20      0.22        65\n",
            "false-positive       0.53      0.59      0.56       205\n",
            " true-negative       0.51      0.46      0.48       184\n",
            " true-positive       0.00      0.00      0.00         0\n",
            "\n",
            "      accuracy                           0.48       454\n",
            "     macro avg       0.32      0.31      0.31       454\n",
            "  weighted avg       0.48      0.48      0.48       454\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzoR-F54NVS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0757fb82-61c6-4242-9733-7c9ab9707525"
      },
      "source": [
        "y_test_np = np.array(Y_test)\n",
        "model_was_right = 0\n",
        "for i in range(len(y_test_np)):\n",
        "    if (y_test_np[i][0] == y_test_pred_np[i][0]):\n",
        "        if (y_test_np[i][1] == y_test_pred_np[i][1]):\n",
        "            model_was_right = model_was_right + 1\n",
        "accuracy = 100*model_was_right/(len(y_test_np))\n",
        "print('Model was right in ', model_was_right, 'from ', len(y_test_np),' observations. So accuracy is ', round(accuracy, 2), '%')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model was right in  219 from  454  observations. So accuracy is  48.24 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX8aoG3lNm6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}